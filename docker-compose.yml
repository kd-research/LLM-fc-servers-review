name: llama-cpp-jupyter

services:
  llama-cpp:
    image: ghcr.io/ggerganov/llama.cpp:full-cuda
    user: "${UID}:${GID}"
    command: --server --host 0.0.0.0 --port 8000 -m ${MODEL}
    ports:
      - "8000"
    networks:
      internal_network:
        aliases:
          - llm
    volumes:
      - /home/kaidong/.llama-cpp/models:/models
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
              count: 1

  jupyter:
    image: jupyter/base-notebook
    ports:
      - "8888:8888"
    networks:
      - internal_network
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./configs/jupyter_notebook_config.py:/home/jovyan/.jupyter/jupyter_notebook_config.py
    env_file:
      - .env

networks:
  internal_network:


